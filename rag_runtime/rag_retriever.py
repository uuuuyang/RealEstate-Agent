# rag_runtime/rag_retriever.py

import json
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from sentence_transformers import CrossEncoder
from config import EMBED_MODEL, RERANK_MODEL, CHROMA_PERSIST_DIR, RETRIEVER_K, RERANK_TOP_N
from cache_manager import cache

COLLECTION_NAME = "jll_units"

class RAGRetriever:
    def __init__(self, persist_dir: str = CHROMA_PERSIST_DIR):
        print("ğŸš€ [System] Initializing Retriever (Embedding + Reranker)...")
        self.embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)
        self.vectordb = Chroma(
            collection_name=COLLECTION_NAME,
            persist_directory=persist_dir,
            embedding_function=self.embeddings
        )
        self.reranker = CrossEncoder(RERANK_MODEL)

    @cache(ttl=3600)  # ç¼“å­˜æ£€ç´¢ç»“æœ1å°æ—¶
    def retrieve(self, query: str, filter_dict: dict = None, k=RETRIEVER_K, rerank_top_n=RERANK_TOP_N):
        print(f"\nğŸ” [Retrieval] Start searching for: '{query}'")
        print(f"   Filter: {filter_dict}")

        # å°†filter_dictè½¬æ¢ä¸ºChromaæ”¯æŒçš„æ ¼å¼
        chroma_filter = self._convert_filter(filter_dict) if filter_dict else None

        # 1. å‘é‡æ£€ç´¢ï¼ˆå¸¦è¿‡æ»¤ï¼‰
        docs = self.vectordb.similarity_search(query, k=k, filter=chroma_filter)
        print(f"   â†³ Initial Recall: {len(docs)} documents")

        if not docs:
            return []

        # 2. Rerank é‡æ’åº
        pairs = [(query, d.page_content) for d in docs]
        scores = self.reranker.predict(pairs)

        doc_scores = list(zip(docs, scores))
        doc_scores.sort(key=lambda x: x[1], reverse=True)

        final_results = doc_scores[:rerank_top_n]

        print(f"ğŸ“‰ [Rerank] Filtered to Top-{rerank_top_n}")

        structured_results = []
        for i, (doc, score) in enumerate(final_results):
            meta = doc.metadata
            print(
                f"   [{i + 1}] Score: {score:.4f} | Year: {meta.get('year')} | District: {meta.get('district')} | Rent: {meta.get('rent')}")
            structured_results.append({
                "text": doc.page_content,
                "meta": doc.metadata
            })

        return structured_results

    def _convert_filter(self, filter_dict: dict) -> dict:
        """å°†è§£æå‡ºçš„è¿‡æ»¤å™¨è½¬æ¢ä¸ºChromaæ”¯æŒçš„$and/$oræ ¼å¼"""
        conditions = []
        for key, value in filter_dict.items():
            if key == "year_range":
                # èŒƒå›´è¿‡æ»¤ï¼šyear >= start and year <= end
                conditions.append({"year": {"$gte": value[0]}})
                conditions.append({"year": {"$lte": value[1]}})
            elif key in ["min_rent", "max_rent", "min_area", "max_area"]:
                # å¤„ç†æ•°å€¼èŒƒå›´ï¼Œå‡è®¾å¯¹åº”å­—æ®µåä¸ºrent/area
                field = key.split("_")[1]
                op = "$gte" if key.startswith("min") else "$lte"
                conditions.append({field: {op: value}})
            else:
                # ç²¾ç¡®åŒ¹é…
                conditions.append({key: {"$eq": value}})
        if len(conditions) == 1:
            return conditions[0]
        elif len(conditions) > 1:
            return {"$and": conditions}
        else:
            return None